import Foundation
import Scraper
import Combine

let fetchCount = 200 // æœ€å¾Œã«ã¯å…¨éƒ¨å–å¾—ã™ã‚‹ã®ã§ä¸è¦ã«ãªã‚‹

// TODO: ç¾çŠ¶ã‚ˆãã‚ã‹ã£ã¦ã„ãªã„ãŒã€`asyncAfter`ã§é…å»¶å®Ÿè¡Œã—ãªã„ã¨`RunLoop`ã®å‡¦ç†ã«åˆ°é”ã—ãªã„ã€‚ã®ã§æš«å®šå¯¾å‡¦

DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
    
    _ = LifeWikiAllPatternPage.fetchAll()
        .flatMap { (pages: [LifeWikiAllPatternPage]) -> AnyPublisher<[LifeWikiPatternPage], Never> in
            print("âš¡ï¸ Start fetch Pattern pages.")
            return pages.map(\.links).joined()
                .prefix(fetchCount)
                .reduce(
                    Just([LifeWikiPatternPage]()).eraseToAnyPublisher()
                ) { (result, link) in
                    result.zip(LifeWikiPatternPage.fetch(url: link))
                        .map { $0.0 + [$0.1] }
                        .eraseToAnyPublisher()
                }
        }
        .flatMap { (pages: [LifeWikiPatternPage]) -> AnyPublisher<[LifeWikiRLE?], Never> in
            print("âš¡ï¸ Start fetch RLE.")
            return pages
                .reduce(
                    Just([LifeWikiRLE?]()).eraseToAnyPublisher()
                ) { (result, page) in
                    if let url = page.rleURL {
                        return result.zip(LifeWikiRLE.fetch(url: url))
                            .map {
                                $0.0 + [$0.1]
                            }
                            .eraseToAnyPublisher()
                    } else {
                        print("âŒ RLE is not found (\(page)") // TODO: source URL ã‚’å‡ºåŠ›ã™ã‚‹ã‚ˆã†ã«
                        return result
                    }
                }
        }
        .sink { rles in
            print("â­ Found \(rles.count) pages.")
            print(rles)
            exit(0)
        }
}

let customMode = "LifeGameScraper"
RunLoop.current.run(mode: RunLoop.Mode(customMode), before: Date.distantFuture)

print("ğŸš€ Run loop started.")
RunLoop.current.run()
