import Foundation
import Scraper
import Combine

let fetchCount = 200 // æœ€å¾Œã«ã¯å…¨éƒ¨å–å¾—ã™ã‚‹ã®ã§ä¸è¦ã«ãªã‚‹

_ = LifeWikiAllPatternPage.fetchAll()
    .flatMap { (pages: [LifeWikiAllPatternPage]) -> AnyPublisher<[LifeWikiPatternPage], Never> in
        print("âš¡ï¸ Start fetch Pattern pages.")
        let initial = Just([LifeWikiPatternPage]()).eraseToAnyPublisher()
        return pages.map(\.links).joined()
            .prefix(fetchCount)
            .reduce(initial) { (result, link) in
                result.zip(LifeWikiPatternPage.fetch(url: link))
                    .map { $0.0 + [$0.1] }
                    .eraseToAnyPublisher()
            }
    }
    .flatMap { (pages: [LifeWikiPatternPage]) -> AnyPublisher<[(LifeWikiPatternPage, LifeWikiRLE?)], Never> in
        print("âš¡ï¸ Start fetch RLE.")
        let initial = Just([LifeWikiRLE?]()).eraseToAnyPublisher()
        return pages
            .reduce(initial) { (result, page) in
                let rlePublisher: AnyPublisher<LifeWikiRLE?, Never>

                if let url = page.rleURL {
                    rlePublisher = LifeWikiRLE.fetch(url: url)
                } else {
                    print("âŒ RLE is not found (\(page.sourceURL)")
                    rlePublisher = Just<LifeWikiRLE?>(nil).eraseToAnyPublisher()
                }
                
                return result.zip(rlePublisher)
                    .map { $0.0 + [$0.1] }
                    .eraseToAnyPublisher()
            }
            .map { rles in
                Array(zip(pages, rles))
            }
            .eraseToAnyPublisher()
        
    }
    .sink { results in
        print("â­ Found \(results.count) pages.")
        let page = results.first!.0
        let rle = results.first!.1
        print("ğŸ“„ \(page)")
        print("ğŸ”– \(rle!)")
        exit(0)
    }

print("ğŸš€ Run loop started.")
RunLoop.current.run()
