import Foundation
import Scraper
import Combine

// TODO: å®Œå…¨ãªä¸¦åˆ—ã‚¹ãƒˆãƒªãƒ¼ãƒ ã«å¤‰æ›´ã™ã‚‹ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã¾ã§ï¼‰

let fetchCount = 100 // æœ€å¾Œã«ã¯å…¨éƒ¨å–å¾—ã™ã‚‹ã®ã§ä¸è¦ã«ãªã‚‹

func scrapeLifeWikiPatterns() -> AnyPublisher<[Result<LifeWikiPattern, ScrapeError>], Never> {
    LifeWikiAllPatternPage.fetchAll()
        .flatMap { (pages: [LifeWikiAllPatternPage]) -> AnyPublisher<[Result<LifeWikiPattern, ScrapeError>], Never> in
            let urls = pages.map(\.patternLinks).joined()
            let initial = Just([Result<LifeWikiPattern, ScrapeError>]()).eraseToAnyPublisher()
            return urls.reduce(initial) { result, url in
                result.zip(
                    LifeWikiPattern.fetch(wikiPageURL: url)
                        .map { pattern ->  Result<LifeWikiPattern, ScrapeError> in
                            Result<LifeWikiPattern, ScrapeError>.success(pattern)
                        }
                        .catch { error in
                            Just(Result<LifeWikiPattern, ScrapeError>.failure(error))
                        }
                        .eraseToAnyPublisher()
                ) { $0 + [$1] }
                .eraseToAnyPublisher()
            }
        }
        .eraseToAnyPublisher()
}

var cancellables: [AnyCancellable] = []

DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
    let start = Date()
    
    scrapeLifeWikiPatterns()
        .sink { (patterns: [Result<LifeWikiPattern, ScrapeError>]) in
            for pattern in patterns {
                switch pattern {
                case let .success(pattern):
                    print("ğŸ '\(pattern.title)' is scraped.")
                
                case let .failure(error):
                    switch error {
                    case .patternPageNotFound:
                        print("ğŸ ãƒšãƒ¼ã‚¸è¦‹ã¤ã‹ã‚“ãªã‹ã£ãŸã‚ˆã€‚")
                    case .rleLinkMissing:
                        print("ğŸŠ RLEãƒªãƒ³ã‚¯ãªã‹ã£ãŸã‚ˆã€‚")
                    case .rleNotFound:
                        print("ğŸ‡ RLEãƒ•ã‚¡ã‚¤ãƒ«ç„¡ã‹ã£ãŸã‚ˆã€‚")
                    }
                }
            }
            print("â­ Scraping is finished. (total: \(patterns.count))")
            
            let elapsed = Date().timeIntervalSince(start)
            print("ğŸŒˆ Finish! (\(elapsed))")
            
            exit(0)
        }
        .store(in: &cancellables)
//    let start = Date()
//
//    _ = LifeWikiAllPatternPage.fetchAll()
//        .flatMap { (pages: [LifeWikiAllPatternPage]) -> AnyPublisher<[LifeWikiPatternPage], Never> in
//            print("âš¡ï¸ Start fetch Pattern pages.")
//            let initial = Just([LifeWikiPatternPage]()).eraseToAnyPublisher()
//            return pages.map(\.patternLinks).joined()
//                .prefix(fetchCount)
//                .reduce(initial) { (result, link) in
//                    result.zip(LifeWikiPatternPage.fetch(url: link))
//                        .map { (result: [LifeWikiPatternPage], page: LifeWikiPatternPage?) in
//                            guard let page = page else { return result }
//                            return result + [page]
//                        }
//                        .eraseToAnyPublisher()
//                }
//        }
//        .map { (pages: [LifeWikiPatternPage]) in
//            pages.filter {
//                let isScraped = LifeWikiPatternHolder.isScraped($0.sourceURL)
//                if isScraped {
//                    print("ğŸŒ¤ Skip because already scraped. (\($0.sourceURL))")
//                }
//                return !isScraped
//            }
//        }
//        .flatMap { (pages: [LifeWikiPatternPage]) -> AnyPublisher<[(LifeWikiPatternPage, LifeWikiRLE?)], Never> in
//            print("âš¡ï¸ Start fetch RLE.")
//            let initial = Just([LifeWikiRLE?]()).eraseToAnyPublisher()
//            return pages
//                .reduce(initial) { (result, page) in
//                    let rlePublisher: AnyPublisher<LifeWikiRLE?, Never>
//
//                    if let url = page.rleURL {
//                        rlePublisher = LifeWikiRLE.fetch(url: url)
//                    } else {
//                        print("â­ Skipped because RLE is not found (\(page.sourceURL))")
//                        rlePublisher = Just<LifeWikiRLE?>(nil).eraseToAnyPublisher()
//                    }
//
//                    return result.zip(rlePublisher)
//                        .map { $0.0 + [$0.1] }
//                        .eraseToAnyPublisher()
//                }
//                .map { rles in
//                    Array(zip(pages, rles))
//                }
//                .eraseToAnyPublisher()
//        }
//        .sink { results in
//            let patterns = results
//                .compactMap {
//                    guard let rle = $0.1 else { return nil }
//                    return ($0.0, rle)
//                }
//                .map { page, rle in
//                    LifeWikiPattern(page: page, rle: rle)
//                }
//
//            print("â­ Found \(patterns.count) pages.")
//
//            for pattern in patterns {
//                print("ğŸ“ Save \(pattern.title)...")
//                LifeWikiPatternHolder.write(pattern)
//            }
//
//            let elapsed = Date().timeIntervalSince(start)
//            print("ğŸŒˆ Finish! (\(elapsed))")
//
//            exit(0)
//        }
}

let customMode = "LifeGameScraper"
RunLoop.current.run(mode: RunLoop.Mode(customMode), before: Date.distantFuture)

print("ğŸš€ Run loop started.")
RunLoop.current.run(until: Date(timeInterval: 1000, since: Date()))
